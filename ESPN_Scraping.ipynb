{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "169de939",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37e998e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name 'pd' is not defined\n"
     ]
    }
   ],
   "source": [
    "# Generate response object\n",
    "try:\n",
    "    # Passing URLs\n",
    "    qb_URLs = ['season/2020', 'season/2021', 'season/2022'] \n",
    "    \n",
    "    # Create empty dataframes for qb, wr, rb.\n",
    "    all_qb_df = pd.DataFrame()\n",
    "    all_rb_df = pd.DataFrame()\n",
    "    all_wr_df = pd.DataFrame()\n",
    "\n",
    "    # Create a for loop for qb data.\n",
    "    for URL in qb_URLs:\n",
    "        Full_URL = 'https://www.espn.com/nfl/stats/player/_/' + URL + '/seasontype/2'\n",
    "        source =  requests.get( Full_URL )\n",
    "        source.raise_for_status()\n",
    "    \n",
    "        # Take webpage text and parse it, then pass it BeautifulSoup Object.\n",
    "        soup = BeautifulSoup(source.text, 'html.parser')\n",
    "        \n",
    "        # Find tbody tag with the specified class 'Table__TBODY'. First is players and stats second\n",
    "        players = soup.find_all('tbody', class_='Table__TBODY')[0].find_all('tr')\n",
    "        stats = soup.find_all('tbody', class_='Table__TBODY')[1].find_all('tr')\n",
    "        \n",
    "        # Create an empty list for players and related stats.\n",
    "        player_list = []\n",
    "        stat_list = []\n",
    "        \n",
    "        # Want to iterate through each 'tr' tag. 1 'tr' tag = 1 player\n",
    "        for player in players:\n",
    "            # Collect all rank, player name, and team name.\n",
    "            rank = player.find_all('td', class_='Table__TD')[0].text\n",
    "            playerName = player.find_all('td', class_='Table__TD')[-1].a.text\n",
    "            team = player.find_all('td', class_='Table__TD')[-1].span.text\n",
    "            \n",
    "            # append all players to list\n",
    "            player_list.append(\n",
    "                {\n",
    "                    'Rank': rank,\n",
    "                    'Player': playerName,\n",
    "                    'Team': team\n",
    "                }\n",
    "            )\n",
    "        \n",
    "        # Convert list to dataframe\n",
    "        player_df = pd.DataFrame(player_list)\n",
    "        \n",
    "        \n",
    "        for indiv_stats in stats:\n",
    "                # Collect all stats\n",
    "                POS = indiv_stats.find_all('td', class_=\"Table__TD\")[0].text\n",
    "                GP = indiv_stats.find_all('td', class_=\"Table__TD\")[1].text\n",
    "                CMP = indiv_stats.find_all('td', class_=\"Table__TD\")[2].text\n",
    "                ATT = indiv_stats.find_all('td', class_=\"Table__TD\")[3].text\n",
    "                CMP_Perc = indiv_stats.find_all('td', class_=\"Table__TD\")[4].text\n",
    "                YDS = indiv_stats.find_all('td', class_=\"Table__TD\")[5].text\n",
    "                AVG = indiv_stats.find_all('td', class_=\"Table__TD\")[6].text\n",
    "                YardsPerG = indiv_stats.find_all('td', class_=\"Table__TD\")[7].text\n",
    "                LNG = indiv_stats.find_all('td', class_=\"Table__TD\")[8].text\n",
    "                TD = indiv_stats.find_all('td', class_=\"Table__TD\")[9].text\n",
    "                INT = indiv_stats.find_all('td', class_=\"Table__TD\")[10].text\n",
    "                SACK = indiv_stats.find_all('td', class_=\"Table__TD\")[11].text\n",
    "                SYL = indiv_stats.find_all('td', class_=\"Table__TD\")[12].text\n",
    "                QBR = indiv_stats.find_all('td', class_=\"Table__TD\")[13].text\n",
    "                RTG = indiv_stats.find_all('td', class_=\"Table__TD\")[14].text\n",
    "                \n",
    "                # Append stats to list\n",
    "                stat_list.append(\n",
    "                {\n",
    "                    'Position': POS,\n",
    "                    'Games Played': GP,\n",
    "                    'Completions': CMP,\n",
    "                    'Attempts': ATT,\n",
    "                    'Completion %': CMP_Perc,\n",
    "                    'Yards': YDS,\n",
    "                    'Average Pass': AVG,\n",
    "                    'Yards Per G': YardsPerG,\n",
    "                    'Long': LNG,\n",
    "                    'Touchdown': TD,\n",
    "                    'Interceptions': INT,\n",
    "                    'Sack': SACK,\n",
    "                    'Sack - Yards lst': SYL,\n",
    "                    'QBR': QBR,\n",
    "                    'Rating': RTG\n",
    "                }\n",
    "                    \n",
    "            )\n",
    "        # Convert list to dataframe\n",
    "        stat_df = pd.DataFrame(stat_list)\n",
    "        stat_df['Year'] = URL.strip(\"season/\")\n",
    "        \n",
    "        # Concatenate columns together\n",
    "        qb_df = pd.concat([player_df, stat_df], axis=1)\n",
    "        \n",
    "        # Stack rows on top of each other\n",
    "        all_qb_df = pd.concat([all_qb_df, qb_df], axis=0)\n",
    "        \n",
    "    # Runningback URLs    \n",
    "    rb_URLs = ['stat/rushing/season/2020', 'stat/rushing/season/2021', 'stat/rushing/season/2022']\n",
    "        \n",
    "    for URL in rb_URLs:\n",
    "        Full_URL = 'https://www.espn.com/nfl/stats/player/_/' + URL + '/seasontype/2'\n",
    "        source =  requests.get( Full_URL )\n",
    "        source.raise_for_status()\n",
    "    \n",
    "        # Take webpage text and parse it, then pass it BeautifulSoup Object.\n",
    "        soup = BeautifulSoup(source.text, 'html.parser')\n",
    "        \n",
    "        # Find tbody tag with the specified class 'Table__TBODY'. First is players and stats second\n",
    "        players = soup.find_all('tbody', class_='Table__TBODY')[0].find_all('tr')\n",
    "        stats = soup.find_all('tbody', class_='Table__TBODY')[1].find_all('tr')\n",
    "        \n",
    "        \n",
    "        # Create an empty list for players and related stats.\n",
    "        player_list = []\n",
    "        stat_list = []\n",
    "        \n",
    "        # Want to iterate through each 'tr' tag. 1 'tr' tag = 1 player\n",
    "        for player in players:\n",
    "            # Collect all rank, player name, and team name.\n",
    "            rank = player.find_all('td', class_='Table__TD')[0].text\n",
    "            playerName = player.find_all('td', class_='Table__TD')[-1].a.text\n",
    "            team = player.find_all('td', class_='Table__TD')[-1].span.text\n",
    "            \n",
    "            # append all players to list\n",
    "            player_list.append(\n",
    "                {\n",
    "                    'Rank': rank,\n",
    "                    'Player': playerName,\n",
    "                    'Team': team\n",
    "                }\n",
    "            )\n",
    "            # Create player dataframe\n",
    "        player_df = pd.DataFrame(player_list)\n",
    "        \n",
    "        \n",
    "        for indiv_stats in stats:\n",
    "            # Collect all stats\n",
    "                POS = indiv_stats.find_all('td', class_=\"Table__TD\")[0].text\n",
    "                GP = indiv_stats.find_all('td', class_=\"Table__TD\")[1].text\n",
    "                ATT = indiv_stats.find_all('td', class_=\"Table__TD\")[2].text\n",
    "                YDS = indiv_stats.find_all('td', class_=\"Table__TD\")[3].text\n",
    "                AVG = indiv_stats.find_all('td', class_=\"Table__TD\")[4].text\n",
    "                LNG = indiv_stats.find_all('td', class_=\"Table__TD\")[5].text\n",
    "                BIG = indiv_stats.find_all('td', class_=\"Table__TD\")[6].text\n",
    "                TD = indiv_stats.find_all('td', class_=\"Table__TD\")[7].text\n",
    "                YDSperG = indiv_stats.find_all('td', class_=\"Table__TD\")[8].text\n",
    "                FUM = indiv_stats.find_all('td', class_=\"Table__TD\")[9].text\n",
    "                LST = indiv_stats.find_all('td', class_=\"Table__TD\")[10].text\n",
    "                FD = indiv_stats.find_all('td', class_=\"Table__TD\")[11].text\n",
    "                \n",
    "                # Append Stats to list\n",
    "                stat_list.append(\n",
    "                {\n",
    "                    'Position': POS,\n",
    "                    'Games Played': GP,\n",
    "                    'Attempts': ATT,\n",
    "                    'Yards': YDS,\n",
    "                    'Average Pass': AVG,\n",
    "                    'Long': LNG,\n",
    "                    'Big': BIG,\n",
    "                    'Touchdown': TD,\n",
    "                    'YDS/G': YDSperG,\n",
    "                    'Fumble': FUM,\n",
    "                    'Lost': LST,\n",
    "                    'First Down': FD\n",
    "                }\n",
    "                    \n",
    "            )\n",
    "        # Turn stats into list\n",
    "        stat_df = pd.DataFrame(stat_list)\n",
    "        stat_df['Year'] = URL.strip(\"stat/rushing/season/\")\n",
    "        \n",
    "        # Concatenate columns together\n",
    "        rb_df = pd.concat([player_df, stat_df], axis=1)\n",
    "        \n",
    "        # Stack rows on top of each other\n",
    "        all_rb_df = pd.concat([all_rb_df, rb_df], axis=0)\n",
    "    \n",
    "    # Wide Receiver URLs\n",
    "    wr_URLs = ['stat/receiving/season/2020', 'stat/receiving/season/2021', 'stat/receiving/season/2022']\n",
    "        \n",
    "    for URL in wr_URLs:\n",
    "        Full_URL = 'https://www.espn.com/nfl/stats/player/_/' + URL + '/seasontype/2'\n",
    "        source =  requests.get( Full_URL )\n",
    "        source.raise_for_status()\n",
    "    \n",
    "        # Take webpage text and parse it, then pass it BeautifulSoup Object.\n",
    "        soup = BeautifulSoup(source.text, 'html.parser')\n",
    "        \n",
    "        # Find tbody tag with the specified class 'Table__TBODY'. First is players and stats second\n",
    "        players = soup.find_all('tbody', class_='Table__TBODY')[0].find_all('tr')\n",
    "        stats = soup.find_all('tbody', class_='Table__TBODY')[1].find_all('tr')\n",
    "        \n",
    "        \n",
    "        # Create an empty list for players and related stats.\n",
    "        player_list = []\n",
    "        stat_list = []\n",
    "        \n",
    "        # Want to iterate through each 'tr' tag. 1 'tr' tag = 1 player\n",
    "        for player in players:\n",
    "            # Collect all rank, player name, and team name.            \n",
    "            rank = player.find_all('td', class_='Table__TD')[0].text\n",
    "            playerName = player.find_all('td', class_='Table__TD')[-1].a.text\n",
    "            team = player.find_all('td', class_='Table__TD')[-1].span.text\n",
    "            \n",
    "            # Append players to list\n",
    "            player_list.append(\n",
    "                {\n",
    "                    'Rank': rank,\n",
    "                    'Player': playerName,\n",
    "                    'Team': team\n",
    "                }\n",
    "            )\n",
    "        # Turn list to dataframe    \n",
    "        player_df = pd.DataFrame(player_list)\n",
    "        \n",
    "        \n",
    "        for indiv_stats in stats:\n",
    "            # Collect all stats\n",
    "                POS = indiv_stats.find_all('td', class_=\"Table__TD\")[0].text\n",
    "                GP = indiv_stats.find_all('td', class_=\"Table__TD\")[1].text\n",
    "                REC = indiv_stats.find_all('td', class_=\"Table__TD\")[2].text\n",
    "                TGTS = indiv_stats.find_all('td', class_=\"Table__TD\")[3].text\n",
    "                YDS = indiv_stats.find_all('td', class_=\"Table__TD\")[4].text\n",
    "                AVG = indiv_stats.find_all('td', class_=\"Table__TD\")[5].text\n",
    "                TD = indiv_stats.find_all('td', class_=\"Table__TD\")[6].text\n",
    "                LNG = indiv_stats.find_all('td', class_=\"Table__TD\")[7].text\n",
    "                BIG = indiv_stats.find_all('td', class_=\"Table__TD\")[8].text\n",
    "                YDSperG = indiv_stats.find_all('td', class_=\"Table__TD\")[9].text\n",
    "                FUM = indiv_stats.find_all('td', class_=\"Table__TD\")[10].text\n",
    "                LST = indiv_stats.find_all('td', class_=\"Table__TD\")[11].text\n",
    "                YAC = indiv_stats.find_all('td', class_=\"Table__TD\")[11].text\n",
    "                FD = indiv_stats.find_all('td', class_=\"Table__TD\")[11].text\n",
    "                \n",
    "                # Append stats to list\n",
    "                stat_list.append(\n",
    "                {\n",
    "                    'Position': POS,\n",
    "                    'Games Played': GP,\n",
    "                    'Receptions': REC,\n",
    "                    'Targets': TGTS,\n",
    "                    'Yards': YDS,\n",
    "                    'Average': AVG,\n",
    "                    'Touchdown': TD,\n",
    "                    'Long': LNG,\n",
    "                    'Big': BIG,\n",
    "                    'Yards per Game': YDSperG,\n",
    "                    'Fumble': FUM,\n",
    "                    'Lost': LST,\n",
    "                    'Yards after Catch': YAC,\n",
    "                    'First Down': FD\n",
    "                }\n",
    "                    \n",
    "            )\n",
    "        # Turn list to dataframe\n",
    "        stat_df = pd.DataFrame(stat_list)\n",
    "        stat_df['Year'] = URL.strip(\"stat/receiving/season/\")\n",
    "        \n",
    "        # Concatenate columns\n",
    "        wr_df = pd.concat([player_df, stat_df], axis=1)\n",
    "        \n",
    "        # Stack all rows.\n",
    "        all_wr_df = pd.concat([all_wr_df, wr_df], axis=0)\n",
    "        \n",
    "        \n",
    "    # Export datframes to CSVs    \n",
    "    all_wr_df.to_csv('wr.csv')\n",
    "    all_rb_df.to_csv('rb.csv')\n",
    "    all_qb_df.to_csv('qb.csv')\n",
    "        \n",
    "            \n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48f0172",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219f9871",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
